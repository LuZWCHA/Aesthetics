{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Espf3gC3iWpB",
        "outputId": "aa1b64cd-9f9c-4207-fe83-39899a411d66"
      },
      "id": "Espf3gC3iWpB",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "\n",
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTRDB8NoZrFp",
        "outputId": "d2b8d213-d3ea-455d-e680-3391fffc0699"
      },
      "id": "dTRDB8NoZrFp",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.1.0.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.64.1)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.12.1+cu113)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil, os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU\n",
        "\n",
        "from torch_geometric.utils import negative_sampling, to_dense_adj\n",
        "from torch_geometric.data import Data#, DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GINConv, GATConv\n",
        "from torch_sparse import SparseTensor\n",
        "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
        "\n",
        "#from logger import Logger\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ],
      "metadata": {
        "id": "ZGpAEKQKZ4tL"
      },
      "id": "ZGpAEKQKZ4tL",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# If you use GPU, the device should be cuda\n",
        "print('Device: {}'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lODtmaPJqg_k",
        "outputId": "697dff98-c5f2-4cf1-af98-fefb7bc24e3d"
      },
      "id": "lODtmaPJqg_k",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(path, picky=False):\n",
        "            mode='TEST'\n",
        "            df=pd.read_csv(path+mode+'annotated_links.csv', names=['source', 'target', 'link'])#.drop('link', axis=1)\n",
        "            if picky==True:\n",
        "              df=df[df['link']==1].drop('link', axis=1)\n",
        "            else:\n",
        "               df=df[df['link']!=0].drop('link', axis=1)\n",
        "            #df.index+=1\n",
        "            #node_ids = df.index\n",
        "            #link = pd.read_csv(path+mode+'annotated_links.csv', names=['source', 'target', 'link'])#['link']\n",
        "            #link.index+=1\n",
        "\n",
        "            cl=pd.read_csv(path+mode+'colours.csv')\n",
        "            #cl.index+=1\n",
        "            di=cl['ImgName'].to_dict()\n",
        "            node2index = {v: k for k, v in di.items()}\n",
        "            df=df.replace({\"source\": node2index}).replace({\"target\": node2index})\n",
        "            cl=cl.drop('ImgName', axis=1)\n",
        "            \n",
        "            node_feats= torch.tensor(cl.to_numpy(), dtype=torch.float)\n",
        "            num_nodes=len(node_feats)\n",
        "            \n",
        "            #edge_feats = torch.tensor(link['link'].to_numpy(), dtype=torch.float)\n",
        "            \n",
        "            #edges = link.loc[link['source'].isin(node_ids)]\n",
        "            edge_index = torch.tensor(df.to_numpy(), dtype=torch.long).T\n",
        "            \n",
        "            data = Data(x=node_feats, edge_index=edge_index,  node2index=node2index, num_nodes=num_nodes)\n",
        "            return data\n",
        "\n",
        "def get_data_split(path, picky=False):\n",
        "    data = get_data(path, picky)\n",
        "    transform = RandomLinkSplit(is_undirected=True)\n",
        "    train_data, val_data, test_data = transform(data)\n",
        "    train_data.edge_index=train_data.edge_index.long()\n",
        "    val_data.edge_index=val_data.edge_index.long()\n",
        "    test_data.edge_index=test_data.edge_index.long()\n",
        "    return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "4Jbid0yscBNu"
      },
      "id": "4Jbid0yscBNu",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anzahl der edges ungerade -> nur je ein Paar f√ºr undirected edges"
      ],
      "metadata": {
        "id": "MFR6X6CNrOz2"
      },
      "id": "MFR6X6CNrOz2"
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/data/GNNrawData/'\n",
        "mode=\"TEST\"\n",
        "PKY=True"
      ],
      "metadata": {
        "id": "NwhoHZlqr5KP"
      },
      "id": "NwhoHZlqr5KP",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dota = get_data(path, picky=PKY)\n",
        "dota.edge_index=dota.edge_index.long()"
      ],
      "metadata": {
        "id": "rEHW_NSIrbBy"
      },
      "id": "rEHW_NSIrbBy",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_t = SparseTensor(row=dota.edge_index[0], col=dota.edge_index[1],\n",
        "                   sparse_sizes=(dota.num_nodes, dota.num_nodes))\n",
        "full_adj_t = to_dense_adj(dota.edge_index)"
      ],
      "metadata": {
        "id": "ZSYLW5xNsHn5"
      },
      "id": "ZSYLW5xNsHn5",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import train_test_split_edges\n",
        "\n",
        "path = '/content/drive/MyDrive/data/GNNrawData/'\n",
        "dataT = get_data(path, picky=PKY)\n",
        "dataT.edge_index=dataT.edge_index.long()\n",
        "# train_data, val_data, test_data = get_data_split(path, picky=PKY)\n",
        "dataT = train_test_split_edges(dataT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGWHmcwnsd3W",
        "outputId": "98c6d3c0-c642-4446-923b-d72501b5c239"
      },
      "id": "vGWHmcwnsd3W",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dota.adj_t=adj_t\n",
        "dota.full_adj_t = to_dense_adj(dota.edge_index)"
      ],
      "metadata": {
        "id": "A5XgYPOz-r0Q"
      },
      "id": "A5XgYPOz-r0Q",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomLinkSpit"
      ],
      "metadata": {
        "id": "GTsb5QdM_XUS"
      },
      "id": "GTsb5QdM_XUS"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "transform = RandomLinkSplit(is_undirected=True, split_labels=True, add_negative_train_samples =True)\n",
        "train_data, val_data, test_data = transform(dota)"
      ],
      "metadata": {
        "id": "R6TZzuyR_CuE"
      },
      "id": "R6TZzuyR_CuE",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLo-S0YAwn0Q",
        "outputId": "bb834a2b-9675-47d4-f582-7cd3572551b9"
      },
      "id": "wLo-S0YAwn0Q",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  0,  4, 18,  7,  1,  7,  3,  9,  0,  7, 13,  8, 15,  1,  4, 10,  1,\n",
              "          0, 10,  8, 15,  9,  7, 14,  8,  5, 17, 13,  0,  3, 19,  5,  0,  4,  4,\n",
              "         10, 14, 17, 12,  7,  4, 18, 20, 10, 20, 17, 18, 11, 11, 18,  1, 18, 14,\n",
              "         17, 17,  7, 18, 20, 19, 19, 11, 14, 19, 10, 19, 17, 15, 15, 19, 16, 18,\n",
              "          4, 20, 17,  3,  9,  8, 12, 15, 18, 19, 10,  6],\n",
              "        [18, 20, 10, 20, 17, 18, 11, 11, 18,  1, 18, 14, 17, 17,  7, 18, 20, 19,\n",
              "         19, 11, 14, 19, 10, 19, 17, 15, 15, 19, 16, 18,  4, 20, 17,  3,  9,  8,\n",
              "         12, 15, 18, 19, 10,  6,  6,  0,  4, 18,  7,  1,  7,  3,  9,  0,  7, 13,\n",
              "          8, 15,  1,  4, 10,  1,  0, 10,  8, 15,  9,  7, 14,  8,  5, 17, 13,  0,\n",
              "          3, 19,  5,  0,  4,  4, 10, 14, 17, 12,  7,  4]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.adj_t =  SparseTensor(row=train_data.edge_index[0], col=train_data.edge_index[1],\n",
        "                   sparse_sizes=(train_data.num_nodes, train_data.num_nodes))\n",
        "train_data.full_adj_t = to_dense_adj(train_data.edge_index)\n",
        "\n",
        "test_data.adj_t =  SparseTensor(row=test_data.edge_index[0], col=test_data.edge_index[1],\n",
        "                   sparse_sizes=(test_data.num_nodes, test_data.num_nodes))\n",
        "test_data.full_adj_t = to_dense_adj(test_data.edge_index)\n",
        "\n",
        "val_data.adj_t =  SparseTensor(row=val_data.edge_index[0], col=val_data.edge_index[1],\n",
        "                   sparse_sizes=(val_data.num_nodes, val_data.num_nodes))\n",
        "val_data.full_adj_t = to_dense_adj(val_data.edge_index)"
      ],
      "metadata": {
        "id": "uYCdZMfxvzb4"
      },
      "id": "uYCdZMfxvzb4",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.to(device) \n",
        "test_data=test_data.to(device) \n",
        "val_data=val_data.to(device) "
      ],
      "metadata": {
        "id": "yeDNj_qJvtdR"
      },
      "id": "yeDNj_qJvtdR",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define models"
      ],
      "metadata": {
        "id": "CZRoff_TcPnH"
      },
      "id": "CZRoff_TcPnH"
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(\n",
        "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
        "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, dim, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = GINConv(\n",
        "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
        "                       Linear(dim, dim), ReLU())) # GINConv takes a neural network as input\n",
        "\n",
        "        self.conv2 = GINConv(\n",
        "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
        "                       Linear(dim, dim), ReLU()))\n",
        "        \n",
        "        self.dropout = dropout\n",
        "  \n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        x = self.conv1(x, adj_t)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, adj_t)\n",
        "        return x\n",
        "\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
        "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for lin in self.lins:\n",
        "            lin.reset_parameters()\n",
        "\n",
        "    def forward(self, x_i, x_j):\n",
        "        x = x_i * x_j\n",
        "        for lin in self.lins[:-1]:\n",
        "            x = lin(x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.lins[-1](x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "kyMq3gKecQIC"
      },
      "id": "kyMq3gKecQIC",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training functions"
      ],
      "metadata": {
        "id": "CAcQVrvbcZHi"
      },
      "id": "CAcQVrvbcZHi"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, predictor, optimizer, batch_size):\n",
        "    model.train()\n",
        "    predictor.train()\n",
        "    pos_train_edge = train_data.pos_edge_label_index.T.to(train_data.x.device)   # HIER ----------------------------------------- #\n",
        "    neg_train_edge = train_data.neg_edge_label_index.T.to(train_data.x.device) \n",
        "\n",
        "    total_loss = total_examples = 0\n",
        "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
        "                           shuffle=True):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        h = model(train_data.x, train_data.adj_t)\n",
        "\n",
        "        edge = pos_train_edge[perm].t()       # HIER ----------------------------------------- #\n",
        "\n",
        "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
        "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
        "\n",
        "        # Instead of negative train edges one could do negative sampling\n",
        "        edge = neg_train_edge[perm].t()\n",
        "        \n",
        "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
        "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
        "\n",
        "        loss = pos_loss + neg_loss\n",
        "        loss.backward()\n",
        "\n",
        "        # torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        num_examples = pos_out.size(0)\n",
        "        total_loss += loss.item() * num_examples\n",
        "        total_examples += num_examples\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, predictor, batch_size):\n",
        "    model.eval()\n",
        "    predictor.eval()\n",
        "\n",
        "    h = model(data.x, data.adj_t)\n",
        "    pos_train_edge = train_data.pos_edge_label_index.T.to(train_data.x.device)# HIER ----------------------------------------- #\n",
        "    neg_train_edge = train_data.neg_edge_label_index.T.to(train_data.x.device)\n",
        "    pos_valid_edge = val_data.pos_edge_label_index.T.to(val_data.x.device)# HIER ----------------------------------------- #\n",
        "    neg_valid_edge = val_data.neg_edge_label_index.T.to(val_data.x.device)# HIER ----------------------------------------- #\n",
        "    pos_test_edge = test_data.pos_edge_label_index.T.to(test_data.x.device)# HIER ----------------------------------------- #\n",
        "    neg_test_edge = test_data.neg_edge_label_index.T.to(test_data.x.device)# HIER ----------------------------------------- #\n",
        "\n",
        "    pos_train_preds = []\n",
        "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
        "        edge = pos_train_edge[perm].t()\n",
        "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
        "\n",
        "    neg_train_preds = []\n",
        "    for perm in DataLoader(range(neg_train_edge.size(0)), batch_size):\n",
        "        edge = neg_train_edge[perm].t()\n",
        "        neg_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    neg_train_pred = torch.cat(neg_train_preds, dim=0)\n",
        "\n",
        "    pos_valid_preds = []\n",
        "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
        "        edge = pos_valid_edge[perm].t()\n",
        "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
        "\n",
        "    neg_valid_preds = []\n",
        "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
        "        edge = neg_valid_edge[perm].t()\n",
        "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
        "\n",
        "    pos_test_preds = []\n",
        "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
        "        edge = pos_test_edge[perm].t()\n",
        "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
        "\n",
        "    neg_test_preds = []\n",
        "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
        "        edge = neg_test_edge[perm].t()\n",
        "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
        "\n",
        "\n",
        "    #print(pos_train_pred)\n",
        "\n",
        "    # ROC AUC\n",
        "    results=[]  \n",
        "\n",
        "    # TRAIN \n",
        "    pos_train_labels = pos_train_edge.size(0)\n",
        "    neg_train_labels = neg_train_edge.size(0)\n",
        "    Etr = pos_train_labels + neg_train_labels\n",
        "\n",
        "    link_labels = torch.zeros(Etr, dtype=torch.float, device=device)\n",
        "    link_labels[:pos_train_labels] = 1\n",
        "\n",
        "    pos_train_preds=torch.cat(pos_train_preds, dim=0)\n",
        "    neg_train_preds=torch.cat(neg_train_preds, dim=0)\n",
        "    link_probs =torch.cat((pos_train_preds,neg_train_preds), dim=0) \n",
        "  \n",
        "    rocauc_train = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
        "\n",
        "\n",
        "    # TEST  \n",
        "    pos_test_labels = pos_test_edge.size(0)\n",
        "    neg_test_labels = neg_test_edge.size(0)\n",
        "    Et = pos_test_labels + neg_test_labels\n",
        "\n",
        "    link_labels = torch.zeros(Et, dtype=torch.float, device=device)\n",
        "    link_labels[:pos_test_labels] = 1\n",
        "\n",
        "    pos_test_preds=torch.cat(pos_test_preds, dim=0)\n",
        "    neg_test_preds=torch.cat(neg_test_preds, dim=0)\n",
        "    link_probs =torch.cat((pos_test_preds,neg_test_preds), dim=0) \n",
        "  \n",
        "    rocauc_test = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
        "\n",
        "    # VAL\n",
        "    pos_val_labels = pos_valid_edge.size(0)\n",
        "    neg_val_labels = neg_valid_edge.size(0)\n",
        "    Ev = pos_val_labels + neg_val_labels\n",
        "\n",
        "    link_labels = torch.zeros(Ev, dtype=torch.float, device=device)\n",
        "    link_labels[:pos_val_labels] = 1\n",
        "\n",
        "    pos_val_preds=torch.cat(pos_valid_preds, dim=0)\n",
        "    neg_val_preds=torch.cat(neg_valid_preds, dim=0)\n",
        "    link_probs =torch.cat((pos_val_preds,neg_val_preds), dim=0) \n",
        " \n",
        "    rocauc_val = roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
        "\n",
        "    results.append(('train', rocauc_train,'| test ', rocauc_test, '| val ', rocauc_val))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "g1fg7VeGcbOc"
      },
      "id": "g1fg7VeGcbOc",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, gnn_args, predictor, model_name): \n",
        "\n",
        "        \n",
        "  for run in range(2):\n",
        "        model.reset_parameters()\n",
        "        predictor.reset_parameters()\n",
        "        optimizer = torch.optim.Adam(\n",
        "            list(model.parameters()) + list(predictor.parameters()),\n",
        "            lr=gnn_args['lr'])\n",
        "\n",
        "\n",
        "        for epoch in range(1, 1 + gnn_args['epochs']):\n",
        "            loss = train(model, predictor, optimizer, gnn_args['batch_size'])\n",
        "\n",
        "            if epoch % gnn_args['eval_steps'] == 0:\n",
        "                results = test(model, predictor, gnn_args['batch_size'])\n",
        "\n",
        "\n",
        "                if epoch % gnn_args['log_steps'] == 0:\n",
        "                    for result in results:\n",
        "                        \n",
        "                        #print(result)\n",
        "                        print(f'Run: {run + 1:02d}, '\n",
        "                              f'Epoch: {epoch:02d}, '\n",
        "                              f'Loss: {loss:.4f}, '\n",
        "                              f'Test: {result}')\n",
        "                    print('---')"
      ],
      "metadata": {
        "id": "mesiAL_vcgt5"
      },
      "id": "mesiAL_vcgt5",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "s8MYU3a-9pad"
      },
      "id": "s8MYU3a-9pad"
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_args = { \n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'hidden_size': 10,\n",
        "    'dropout': 0.5,\n",
        "    'epochs': 10,\n",
        "    'weight_decay': 1e-5,\n",
        "    'lr': 0.005,\n",
        "    'attn_size': 32,\n",
        "    'num_layers':2,\n",
        "    'log_steps':1,\n",
        "    'eval_steps':1,\n",
        "    'runs':10,\n",
        "    'batch_size': 6\n",
        "}"
      ],
      "metadata": {
        "id": "jI24FgcE9r3O"
      },
      "id": "jI24FgcE9r3O",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dota.to(device)"
      ],
      "metadata": {
        "id": "KSNPgb4kvgcx"
      },
      "id": "KSNPgb4kvgcx",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'sage'\n",
        "input_size = dota.x.size(1)\n",
        "sage_model = SAGE(input_size, gnn_args['hidden_size'], gnn_args['hidden_size'], \n",
        "              gnn_args['num_layers'], gnn_args['dropout']).to(device)  \n",
        "predictor = LinkPredictor(gnn_args['hidden_size'], gnn_args['hidden_size'], 1,\n",
        "                          gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "train_model(sage_model, gnn_args, predictor, 'sage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF4Acwf29k1s",
        "outputId": "2a045bd5-820d-477b-9bfa-0408c8053050"
      },
      "id": "dF4Acwf29k1s",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 01, Loss: 1.4431, Test: ('train', 0.6757369614512472, '| test ', 0.4861111111111111, '| val ', 0.8055555555555556)\n",
            "---\n",
            "Run: 01, Epoch: 02, Loss: 1.3994, Test: ('train', 0.6882086167800454, '| test ', 0.47916666666666663, '| val ', 0.7777777777777779)\n",
            "---\n",
            "Run: 01, Epoch: 03, Loss: 1.3826, Test: ('train', 0.7046485260770976, '| test ', 0.5069444444444444, '| val ', 0.8333333333333334)\n",
            "---\n",
            "Run: 01, Epoch: 04, Loss: 1.3972, Test: ('train', 0.7040816326530612, '| test ', 0.4930555555555556, '| val ', 0.8333333333333334)\n",
            "---\n",
            "Run: 01, Epoch: 05, Loss: 1.3491, Test: ('train', 0.7046485260770975, '| test ', 0.5, '| val ', 0.7777777777777779)\n",
            "---\n",
            "Run: 01, Epoch: 06, Loss: 1.3383, Test: ('train', 0.7057823129251701, '| test ', 0.5277777777777777, '| val ', 0.8611111111111112)\n",
            "---\n",
            "Run: 01, Epoch: 07, Loss: 1.4151, Test: ('train', 0.7029478458049887, '| test ', 0.5, '| val ', 0.888888888888889)\n",
            "---\n",
            "Run: 01, Epoch: 08, Loss: 1.3533, Test: ('train', 0.7148526077097506, '| test ', 0.5277777777777778, '| val ', 0.9166666666666667)\n",
            "---\n",
            "Run: 01, Epoch: 09, Loss: 1.3205, Test: ('train', 0.7057823129251701, '| test ', 0.5416666666666667, '| val ', 0.888888888888889)\n",
            "---\n",
            "Run: 01, Epoch: 10, Loss: 1.4365, Test: ('train', 0.7097505668934241, '| test ', 0.5416666666666667, '| val ', 0.888888888888889)\n",
            "---\n",
            "Run: 02, Epoch: 01, Loss: 1.4053, Test: ('train', 0.5708616780045352, '| test ', 0.5, '| val ', 0.8333333333333334)\n",
            "---\n",
            "Run: 02, Epoch: 02, Loss: 1.3862, Test: ('train', 0.5912698412698413, '| test ', 0.5138888888888888, '| val ', 0.8333333333333334)\n",
            "---\n",
            "Run: 02, Epoch: 03, Loss: 1.3962, Test: ('train', 0.6043083900226757, '| test ', 0.5, '| val ', 0.888888888888889)\n",
            "---\n",
            "Run: 02, Epoch: 04, Loss: 1.3872, Test: ('train', 0.6162131519274376, '| test ', 0.4652777777777778, '| val ', 0.8611111111111112)\n",
            "---\n",
            "Run: 02, Epoch: 05, Loss: 1.3673, Test: ('train', 0.63718820861678, '| test ', 0.5, '| val ', 0.9166666666666667)\n",
            "---\n",
            "Run: 02, Epoch: 06, Loss: 1.3797, Test: ('train', 0.6541950113378686, '| test ', 0.5694444444444444, '| val ', 0.8333333333333334)\n",
            "---\n",
            "Run: 02, Epoch: 07, Loss: 1.3603, Test: ('train', 0.6819727891156463, '| test ', 0.625, '| val ', 0.8611111111111112)\n",
            "---\n",
            "Run: 02, Epoch: 08, Loss: 1.3745, Test: ('train', 0.6729024943310657, '| test ', 0.6111111111111112, '| val ', 0.7222222222222222)\n",
            "---\n",
            "Run: 02, Epoch: 09, Loss: 1.3648, Test: ('train', 0.6258503401360545, '| test ', 0.5486111111111112, '| val ', 0.7777777777777779)\n",
            "---\n",
            "Run: 02, Epoch: 10, Loss: 1.3877, Test: ('train', 0.6286848072562359, '| test ', 0.6041666666666667, '| val ', 0.7777777777777779)\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gcn'\n",
        "input_size = dataT.x.size(1)\n",
        "gcn_model = GCN(input_size, gnn_args['hidden_size'], gnn_args['hidden_size'], \n",
        "              gnn_args['num_layers'], gnn_args['dropout']).to(device)  \n",
        "predictor = LinkPredictor(gnn_args['hidden_size'], gnn_args['hidden_size'], 1,\n",
        "                          gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "train_model(gcn_model, gnn_args, predictor, 'gcn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E5AfcNTSYYj",
        "outputId": "3683236a-1ebf-4443-c4e9-480825aac80a"
      },
      "id": "3E5AfcNTSYYj",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 02, Loss: 1.3968, Test: ('train', 0.41043083900226757, '| test ', 0.3402777777777778, '| val ', 0.7222222222222223)\n",
            "---\n",
            "Run: 01, Epoch: 04, Loss: 1.3873, Test: ('train', 0.6740362811791383, '| test ', 0.4930555555555556, '| val ', 0.888888888888889)\n",
            "---\n",
            "Run: 01, Epoch: 06, Loss: 1.3838, Test: ('train', 0.778344671201814, '| test ', 0.5555555555555556, '| val ', 0.9166666666666667)\n",
            "---\n",
            "Run: 01, Epoch: 08, Loss: 1.3860, Test: ('train', 0.7936507936507937, '| test ', 0.5625, '| val ', 0.9166666666666667)\n",
            "---\n",
            "Run: 01, Epoch: 10, Loss: 1.3802, Test: ('train', 0.8027210884353742, '| test ', 0.5625, '| val ', 0.9166666666666667)\n",
            "---\n",
            "Run: 02, Epoch: 02, Loss: 1.3799, Test: ('train', 0.49829931972789115, '| test ', 0.5208333333333334, '| val ', 0.5833333333333334)\n",
            "---\n",
            "Run: 02, Epoch: 04, Loss: 1.3799, Test: ('train', 0.5736961451247166, '| test ', 0.5277777777777778, '| val ', 0.6944444444444444)\n",
            "---\n",
            "Run: 02, Epoch: 06, Loss: 1.3844, Test: ('train', 0.6950113378684807, '| test ', 0.7430555555555555, '| val ', 0.5)\n",
            "---\n",
            "Run: 02, Epoch: 08, Loss: 1.3978, Test: ('train', 0.7454648526077098, '| test ', 0.7222222222222222, '| val ', 0.5277777777777778)\n",
            "---\n",
            "Run: 02, Epoch: 10, Loss: 1.3793, Test: ('train', 0.7766439909297053, '| test ', 0.7569444444444444, '| val ', 0.638888888888889)\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gin'\n",
        "input_size = dataT.x.size(1)\n",
        "gin_model = GIN(input_size, gnn_args['hidden_size'], gnn_args['hidden_size'], \n",
        "              gnn_args['num_layers'], gnn_args['dropout']).to(device)  \n",
        "predictor = LinkPredictor(gnn_args['hidden_size'], gnn_args['hidden_size'], 1,\n",
        "                          gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "train_model(gin_model, gnn_args, predictor, 'gin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CRrbsGz_vxc",
        "outputId": "6dd014ae-d128-4582-8214-c5966947ab87"
      },
      "id": "5CRrbsGz_vxc",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 02, Loss: 1.3901, Test: ('train', 0.7930839002267575, '| test ', 0.7013888888888888, '| val ', 1.0)\n",
            "---\n",
            "Run: 01, Epoch: 04, Loss: 1.3252, Test: ('train', 0.782312925170068, '| test ', 0.6805555555555556, '| val ', 1.0)\n",
            "---\n",
            "Run: 01, Epoch: 06, Loss: 1.2081, Test: ('train', 0.774092970521542, '| test ', 0.6736111111111112, '| val ', 1.0)\n",
            "---\n",
            "Run: 01, Epoch: 08, Loss: 1.1500, Test: ('train', 0.7570861678004536, '| test ', 0.6180555555555556, '| val ', 1.0)\n",
            "---\n",
            "Run: 01, Epoch: 10, Loss: 1.1373, Test: ('train', 0.7534013605442177, '| test ', 0.6284722222222222, '| val ', 1.0)\n",
            "---\n",
            "Run: 02, Epoch: 02, Loss: 1.4019, Test: ('train', 0.780045351473923, '| test ', 0.625, '| val ', 1.0)\n",
            "---\n",
            "Run: 02, Epoch: 04, Loss: 1.3807, Test: ('train', 0.7658730158730159, '| test ', 0.6249999999999999, '| val ', 1.0)\n",
            "---\n",
            "Run: 02, Epoch: 06, Loss: 1.3739, Test: ('train', 0.7573696145124719, '| test ', 0.6666666666666666, '| val ', 1.0)\n",
            "---\n",
            "Run: 02, Epoch: 08, Loss: 1.3123, Test: ('train', 0.731859410430839, '| test ', 0.6319444444444444, '| val ', 0.9444444444444445)\n",
            "---\n",
            "Run: 02, Epoch: 10, Loss: 1.1990, Test: ('train', 0.6947278911564626, '| test ', 0.5416666666666666, '| val ', 0.9166666666666666)\n",
            "---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 169.835995,
      "end_time": "2022-09-10T08:20:15.390971",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-09-10T08:17:25.554976",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}